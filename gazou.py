# ç›®çš„ï¼šç”»åƒã®ã€Œæš—ã™ãï¼æ˜ã‚‹ã™ãã€ã‚’æŠ‘ãˆã¦ã€è¦‹ã‚„ã™ã„ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã«èª¿æ•´ã™ã‚‹
# æ‰‹é †ï¼š
#  ç”»ç´ å€¤ã®ä¸‹ã‹ã‚‰2%ï¼ä¸Šã‹ã‚‰2%ã«å½“ãŸã‚‹å€¤ p2ï¼p98 ã‚’å–å¾—ï¼ˆå¤–ã‚Œå€¤ã‚’é™¤ãï¼‰
#  np.clip ã§ç”»ç´ å€¤ã‚’ [p2, p98] ã«åˆ¶é™
#  0â€“255 ã®ç¯„å›²ã«ãƒªã‚¹ã‚±ãƒ¼ãƒ«ã—ã¦ uint8 å‹ã«å¤‰æ›


def normalize_slice(slice_data):
    """
    Normalize slice data using 2nd and 98th percentiles for better contrast
    """
    p2 = np.percentile(slice_data, 2)
    p98 = np.percentile(slice_data, 98)
    clipped_data = np.clip(slice_data, p2, p98)
    normalized = 255 * (clipped_data - p2) / (p98 - p2)
    return np.uint8(normalized)


# ç›®çš„ï¼šæ¬¡ã®æ¨è«–ãƒãƒƒãƒã«ä½¿ã†ç”»åƒã‚’ã€å‰ã‚‚ã£ã¦ï¼ˆä¸¦è¡Œã—ã¦ï¼‰èª­ã¿è¾¼ã‚“ã§ãŠã
# æµã‚Œï¼š
#  OpenCV (cv2.imread) ã§èª­ã‚ãªã‘ã‚Œã° PIL (Image.open) ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
#  ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¦ã¾ã¨ã‚ã¦è¿”ã™


def preload_image_batch(file_paths):
    """Preload a batch of images to CPU memory"""
    images = []
    for path in file_paths:
        img = cv2.imread(path)
        if img is None:
            # OpenCVã§èª­ã‚ãªã„å ´åˆã¯PILã§å†ãƒˆãƒ©ã‚¤
            img = np.array(Image.open(path))
        images.append(img)
    return images

# 1ã¤ã®ãƒˆãƒ¢ã‚°ãƒ©ãƒ ï¼ˆæ–­å±¤åƒã‚»ãƒƒãƒˆï¼‰ã«å¯¾ã—ã¦ã€Œãƒãƒƒãƒå‡¦ç†ï¼‹ä¸¦åˆ—åŒ–ï¼‹GPUã‚¹ãƒˆãƒªãƒ¼ãƒ ã€ã§ 
# YOLO æ¨è«–ã‚’è¡Œã„ã€ã€Œæœ€ã‚‚ç¢ºä¿¡åº¦ã®é«˜ã„ãƒ¢ãƒ¼ã‚¿ãƒ¼ä½ç½®ã€ã‚’è¿”ã™é–¢æ•°
def process_tomogram(tomo_id, model, index=0, total=1):
    """
    Process a single tomogram and return the most confident motor detection
    """
    # print(f"Processing tomogram {tomo_id} ({index}/{total})")
    
    # test_dir/tomo_id ãƒ•ã‚©ãƒ«ãƒ€å†…ã® .jpg ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã™ã¹ã¦å–å¾—ã—ã€ã‚½ãƒ¼ãƒˆã—ã¦ãƒªã‚¹ãƒˆåŒ–
    tomo_dir = os.path.join(test_dir, tomo_id)
    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])

    # CONCENTRATIONï¼šå…¨ã‚¹ãƒ©ã‚¤ã‚¹ã®ã†ã¡ã€Œä½•å‰²ã‚’ä½¿ã†ã‹ã€ã‚’ç¤ºã™ï¼ˆä¾‹ 1.0ï¼100%, 0.5ï¼åŠåˆ†ï¼‰
    # np.linspace ã§ç­‰é–“éš”ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–ã‚Šã€round ã—ã¦æ•´æ•°åŒ–â†’é–“å¼•ãã—ãŸã‚¹ãƒ©ã‚¤ã‚¹ãƒªã‚¹ãƒˆã«æ›´æ–°
    # ã“ã‚Œã«ã‚ˆã‚Šã€Œå‡¦ç†é‡ã‚’æ¸›ã‚‰ã—ãŸã„ã€ã€Œã–ã£ã¨å…¨ä½“ã‚’ã–ã£ãã‚Šè¦‹ã‚‹ã€ã‚ˆã†ãªè¨­å®šãŒå¯èƒ½

    selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * CONCENTRATION))
    selected_indices = np.round(selected_indices).astype(int)
    slice_files = [slice_files[i] for i in selected_indices]
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆtorch.cuda.Streamï¼‰ï¼šCUDA ã®éåŒæœŸå®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    # è¤‡æ•°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ç”¨æ„ã—ã¦ãƒãƒƒãƒå†…ã‚’ã•ã‚‰ã«ä¸¦åˆ—åŒ–ã—ã€GPU ã®ç©ºããƒªã‚½ãƒ¼ã‚¹ã‚’åŠ¹ç‡åˆ©ç”¨
    # ã‚¹ãƒˆãƒªãƒ¼ãƒ æ•°ã¯ BATCH_SIZE ã¨æœ€å¤§ï¼”ã®å°ã•ã„æ–¹

    if device.startswith('cuda'):
        å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ = [torch.cuda.Stream() for _ in range(min(4, BATCH_SIZE))]
    else:
        å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ = [None]
    
    # all_detectionsï¼šã“ã®ãƒˆãƒ¢ã‚°ãƒ©ãƒ å†…ã®å…¨ã‚¹ãƒ©ã‚¤ã‚¹ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæ¤œå‡ºçµæœã‚’ç´¯ç©
    # next_batch_threadï¼šæ¬¡ã®ãƒãƒƒãƒç”»åƒã‚’å…ˆèª­ã¿ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä¿æŒ
    all_detections = []
    next_batch_thread = None
    next_batch_images = None
    
    # ãƒãƒƒãƒå˜ä½ã§ãƒ«ãƒ¼ãƒ—
    # ã€€batch_start ã‚’ 0 ï½ ã‚¹ãƒ©ã‚¤ã‚¹æ•° ã¾ã§ BATCH_SIZE é–“éš”ã§åˆ»ã‚€ã€‚
    # ã€€å‰å›ç«‹ã¡ä¸Šã’ãŸãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ (next_batch_thread) ãŒã‚ã‚Œã° .join() ã—ã¦å®Œäº†ã‚’å¾…æ©Ÿã€‚
    for batch_start in range(0, len(slice_files), BATCH_SIZE):
        # Wait for previous preload thread if it exists
        if next_batch_thread is not None:
            next_batch_thread.join()
            next_batch_images = None
        # batch_filesï¼šä»Šã™ãæ¨è«–ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
        batch_end = min(batch_start + BATCH_SIZE, len(slice_files))
        batch_files = slice_files[batch_start:batch_end]
        
        # next_batch_filesï¼šæ¬¡ãƒ«ãƒ¼ãƒ—ã§ä½¿ã†ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
        next_batch_start = batch_end
        next_batch_end = min(next_batch_start + BATCH_SIZE, len(slice_files))
        next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []
        

        # threading.Thread ã‚’ä½¿ã„ã€åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§ preload_image_batchï¼ˆOpenCV/PIL ã§ã®ç”»åƒèª­ã¿è¾¼ã¿ï¼‰ã‚’å®Ÿè¡Œ
        # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã¯ãã®é–“ã«ç¾åœ¨ãƒãƒƒãƒã‚’å‡¦ç†
        if next_batch_files:
            next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]
            next_batch_thread = threading.Thread(target=preload_image_batch, args=(next_batch_paths,))
            next_batch_thread.start()
        else:
            next_batch_thread = None
        
        # ã‚µãƒ–ãƒãƒƒãƒã«åˆ†å‰²ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒ ã”ã¨ã«æ¨è«–
        # batch_files: ä»Šå›ã¾ã¨ã‚ã¦å‡¦ç†ã™ã‚‹ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
        # å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ: ç”¨æ„ã—ãŸ CUDA ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆï¼ˆGPU ã‚’ä½¿ã‚ãªã„å ´åˆã¯ [None]ï¼‰
        # Python ã®ãƒªã‚¹ãƒˆ batch_files ã‚’ã€streams ã®æ•°ã ã‘å‡ç­‰ã«åˆ†å‰²ã€‚
        # ãŸã¨ãˆã°ãƒãƒƒãƒã« 8 æšã®ç”»åƒãŒã‚ã£ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒ æ•°ãŒ 2 ãªã‚‰ã€4 æšãšã¤ã«åˆ†ã‹ã‚Œã¾ã™ã€‚
        # ã“ã‚Œã‚’ sub_batches ã¨å‘¼ã³ã¾ã™ã€‚

        # i % len(å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ) ã§ã€ã‚µãƒ–ãƒãƒƒãƒ i ã«å‰²ã‚Šå½“ã¦ã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å¾ªç’°çš„ã«é¸ã³ã¾ã™ã€‚
        # ã“ã†ã™ã‚‹ã¨ã€Œã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼‘ã«ã¯ã‚µãƒ–ãƒãƒƒãƒï¼‘ã¨ï¼“ã¨ï¼•â€¦ã€ã€Œã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼’ã«ã¯ã‚µãƒ–ãƒãƒƒãƒï¼’ã¨ï¼”â€¦ã€ã®ã‚ˆã†ã«åˆ†æ•£ã•ã‚Œã¾ã™ã€‚
        sub_batches = np.array_split(batch_files, len(å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ))
        sub_batch_results = []
        
        for i, sub_batch in enumerate(sub_batches):
            if len(sub_batch) == 0:
                continue
                
            stream = å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ[i % len(å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ)]
            with torch.cuda.stream(stream) if stream and device.startswith('cuda') else nullcontext():
                # Process sub-batch
                sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]
                sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]
                
                # GPUProfiler ã¯ã€Œã“ã“ã‹ã‚‰ã“ã“ã¾ã§ GPU ã®å‡¦ç†æ™‚é–“ã‚’æ¸¬ã‚‹ã€ãŸã‚ã®ä»•æ›ã‘ã€‚
                # model(sub_batch_paths) ã§ YOLO ãƒ¢ãƒ‡ãƒ«ã«ä¸€æ°—ã«è¤‡æ•°ç”»åƒã‚’æ¸¡ã—ã€ç‰©ä½“æ¤œå‡ºã‚’è¡Œã„ã¾ã™ã€‚
                # æˆ»ã‚Šå€¤ sub_results ã¯ã€å„ç”»åƒã«ã¤ã 1 ä»¶ã®ã€Œçµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãŒå…¥ã£ãŸãƒªã‚¹ãƒˆã§ã™ã€‚
                with GPUProfiler(f"Inference batch {i+1}/{len(sub_batches)}"):
                    sub_results = model(sub_batch_paths, verbose=False)
                
                # æ¨è«–çµæœã®å¾Œå‡¦ç†
                    # result.boxesï¼šæ¤œå‡ºã•ã‚ŒãŸçŸ©å½¢ï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼‰æƒ…å ±ã®ã¾ã¨ã¾ã‚Š
                    # boxes.confï¼šå„ãƒœãƒƒã‚¯ã‚¹ã”ã¨ã®ã€Œã“ã®äºˆæ¸¬ãŒæ­£è§£ã®ç¢ºä¿¡åº¦ã€
                    # boxes.xyxyï¼šå·¦ä¸Š (x1,y1)ï¼å³ä¸‹ (x2,y2) ã®åº§æ¨™
                    # ç¢ºä¿¡åº¦ãŒ CONFIDENCE_THRESHOLD ä»¥ä¸Šãªã‚‰æ¡ç”¨
                    # ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒã‚’ (x1+x2)/2, (y1+y2)/2 ã§è¨ˆç®—
                    # ã‚¹ãƒ©ã‚¤ã‚¹ç•ªå· z ã¨ã‚ã‚ã›ã¦ all_detections ã«æ ¼ç´
                    
                for j, result in enumerate(sub_results):
                    if len(result.boxes) > 0:
                        boxes = result.boxes
                        for box_idx, confidence in enumerate(boxes.conf):
                            if confidence >= CONFIDENCE_THRESHOLD:
                                # Get bounding box coordinates
                                x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()
                                
                                # Calculate center coordinates
                                x_center = (x1 + x2) / 2
                                y_center = (y1 + y2) / 2
                                
                                # Store detection with 3D coordinates
                                all_detections.append({
                                    'z': round(sub_batch_slice_nums[j]),
                                    'y': round(y_center),
                                    'x': round(x_center),
                                    'confidence': float(confidence)
                                })
        
        # å…¨ã‚µãƒ–ãƒãƒƒãƒçµ‚äº†å¾Œã® GPU åŒæœŸ
        if device.startswith('cuda'):
            torch.cuda()
    

    # all_detectionsï¼šã“ã®ãƒˆãƒ¢ã‚°ãƒ©ãƒ å…¨ä½“ã‹ã‚‰é›†ã‚ãŸã€Œ3Dåº§æ¨™ï¼‹ä¿¡é ¼åº¦ã€ã®ãƒªã‚¹ãƒˆ
    # 3D NMS ã§è¿‘æ¥æ¤œå‡ºã‚’ãƒãƒ¼ã‚¸
    # ä¿¡é ¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
    # ä¸€ç•ªä¿¡é ¼åº¦ã®é«˜ã„ã‚‚ã®ã ã‘ã‚’æœ€çµ‚çµæœã¨ã—ã¦è¿”å´
    # ã‚‚ã—æ¤œå‡ºãŒä¸€ã¤ã‚‚ãªã‘ã‚Œã° -1, -1, -1 ã‚’è¿”ã™
    if next_batch_thread is not None:
        next_batch_thread.join()
    
    final_detections = perform_3d_nms(all_detections, NMS_IOU_THRESHOLD)
    
    final_detections.sort(key=lambda x: x['confidence'], reverse=True)
    
    if not final_detections:
        return {
            'tomo_id': tomo_id,
            'Motor axis 0': -1,
            'Motor axis 1': -1,
            'Motor axis 2': -1
        }
    
    best_detection = final_detections[0]
    
    return {
        'tomo_id': tomo_id,
        'Motor axis 0': round(best_detection['z']),
        'Motor axis 1': round(best_detection['y']),
        'Motor axis 2': round(best_detection['x'])
    }

# ğŸ“‹ ç›®çš„
    # åŒã˜ãƒ¢ãƒ¼ã‚¿ãƒ¼ã‚’è¤‡æ•°ã‚¹ãƒ©ã‚¤ã‚¹ã§æ¤œå‡ºã—ã¦ã—ã¾ã£ãŸã¨ãã«ã€ã€Œè¿‘æ¥ã—ã¦ã„ã‚‹ã‚‚ã®ã€ã‚’ã¾ã¨ã‚ã¦ä¸€ã¤ã«çµã‚Šè¾¼ã‚€ã€‚

# ğŸ”§ å…¥åŠ›
    # detectionsï¼š
    # å„è¦ç´ ãŒ { 'z':â€¦, 'y':â€¦, 'x':â€¦, 'confidence':â€¦ } ã®è¾æ›¸ã®ãƒªã‚¹ãƒˆ
    # z, y, x ã¯ãã‚Œãã‚Œã‚¹ãƒ©ã‚¤ã‚¹ç•ªå·ãƒ»è¡Œãƒ»åˆ—ã®ä½ç½®ã€confidence ã¯æ¤œå‡ºç¢ºä¿¡åº¦
    # iou_thresholdï¼š
    # ã€Œã©ã‚Œã ã‘è¿‘ã‘ã‚Œã°åŒä¸€ã¨ã¿ãªã™ã‹ã€ã‚’æ±ºã‚ã‚‹è·é›¢ã®ã—ãã„å€¤ä¿‚æ•°

def perform_3d_nms(detections, iou_threshold):
    """
    Perform 3D Non-Maximum Suppression on detections to merge nearby motors
    """
    # æ¤œå‡ºãŒä¸€ã¤ã‚‚ãªã‘ã‚Œã°ã€ãã®ã¾ã¾ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã—ã¾ã™ã€‚
    if not detections:
        return []
    
    # ä¸€ç•ªã€Œè‡ªä¿¡ã®ã‚ã‚‹ã€æ¤œå‡ºã‹ã‚‰é †ã«å‡¦ç†ã‚’å§‹ã‚ã‚‹ãŸã‚ã«ã€ä¸¦ã³æ›¿ãˆã€‚
    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
    
    # Define 3D distance function
    def distance_3d(d1, d2):
        return np.sqrt((d1['z'] - d2['z'])**2 + 
                       (d1['y'] - d2['y'])**2 + 
                       (d1['x'] - d2['x'])**2)

    # ã€Œãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º Ã— å·®ã—å¼•ãé–¾å€¤ä¿‚æ•°ã€ã§ã€â€è¿‘ã„â€ ã¨ã¿ãªã™æœ€å¤§è·é›¢ã‚’æ±ºå®šã€‚
    box_size = 24  # Same as annotation box size
    distance_threshold = box_size * iou_threshold
    

    # æœ€é«˜ç¢ºä¿¡åº¦ã®æ¤œå‡ºã‚’ã²ã¨ã¤é¸ã¶
    # ãã‚Œã‚’ã€Œç¢ºå®šã€ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹
    # ã€Œç¢ºå®šã€ã—ãŸä½ç½®ã‹ã‚‰ distance_threshold ä»¥ä¸‹ã®è·é›¢ã«ã‚ã‚‹å€™è£œã‚’ã™ã¹ã¦é™¤ã
    # æ®‹ã‚Šã§åŒã˜å‡¦ç†ã‚’ç¹°ã‚Šè¿”ã™
    final_detections = []
    while detections:
        best_detection = detections.pop(0)
        final_detections.append(best_detection)
        
        detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]
    
    return final_detections


# ğŸ“‹ ç›®çš„
#   ãƒˆãƒ¢ã‚°ãƒ©ãƒ ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãèª­ã‚ã‚‹ã‹ã€ã„ãã¤ã‹ã®æ–¹æ³•ã§è©¦ã—èª­ã¿ã—ã¦å•é¡ŒãŒãªã„ã‹ã‚’ç¢ºèªã™ã‚‹

# ğŸ”§ å…¥åŠ›
#   tomo_idï¼š
#   èª¿ã¹ãŸã„ãƒˆãƒ¢ã‚°ãƒ©ãƒ ãƒ•ã‚©ãƒ«ãƒ€å
def debug_image_loading(tomo_id):
    """
    Debug function to check image loading
    """
    tomo_dir = os.path.join(test_dir, tomo_id)
    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])
    
    if not slice_files:
        print(f"No image files found in {tomo_dir}")
        return

    # ãƒªã‚¹ãƒˆã®çœŸã‚“ä¸­ã«ã‚ã‚‹ç”»åƒã‚’ä»£è¡¨ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦é¸æŠã€‚    
    sample_file = slice_files[len(slice_files)//2]  # Middle slice
    img_path = os.path.join(tomo_dir, sample_file)
    

    # PIL â†’ Image.open â†’ é…åˆ—åŒ–
    # OpenCV â†’ cv2.imread
    # OpenCVï¼‹è‰²å¤‰æ› â†’ RGBã«ç›´ã™
    # ã„ãšã‚Œã‹ã§ä¾‹å¤–ãŒå‡ºãŸã‚‰ã€ã©ã®æ–¹æ³•ã§å¤±æ•—ã—ãŸã‹ã‚’å‡ºåŠ›ã€‚
    try:
        # Method 1: PIL
        img_pil = Image.open(img_path)
        img_array_pil = np.array(img_pil)
        
        # Method 2: OpenCV
        img_cv2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        # print(f"OpenCV Image shape: {img_cv2.shape}, dtype: {img_cv2.dtype}")
        
        # Method 3: Convert to RGB
        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)
    except Exception as e:
        print(f"Error loading image {img_path}: {e}")
        
    # Also test with YOLO's built-in loader
    try:
        test_model = YOLO(model_path)
        test_results = test_model([img_path], verbose=False)
        # print("YOLO model successfully processed the test image")
    except Exception as e:
        print(f"Error with YOLO processing: {e}")

# ãƒ†ã‚¹ãƒˆç”¨ãƒˆãƒ¢ã‚°ãƒ©ãƒ å…¨ä½“ã‚’ä¸€æ°—ã«å‡¦ç†ã—ã€ã€Œæå‡ºç”¨ CSVã€ã‚’ä½œæˆã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒãƒ³
def generate_submission():
    """
    Main function to generate the submission file
    """
    test_tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])
    total_tomos = len(test_tomos)
    
    if test_tomos:
        debug_image_loading(test_tomos[0])
    
    # GPU ã‚’ä½¿ã†å ´åˆã€PyTorch ãŒä¿æŒã—ã¦ã„ã‚‹ä¸è¦ãª GPU ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢
    # ã“ã‚Œã§ä»¥é™ã®å‡¦ç†ã«æœ€å¤§é™ãƒ¡ãƒ¢ãƒªã‚’å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ã‚ˆã†ã«æº–å‚™
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    model = YOLO(model_path)
    model.to(device)
    
    GPU æœ€é©åŒ–

    # model.fuse()
    #   ç•³ã¿è¾¼ã¿å±¤ï¼ˆConvï¼‰ï¼‹ãƒãƒƒãƒæ­£è¦åŒ–å±¤ï¼ˆBatchNormï¼‰ã‚’çµåˆã—ã€æ¨è«–é€Ÿåº¦ã‚’å‘ä¸Š
    # model.model.half()
    #   GPU ãŒ Ampere ä»¥é™ï¼ˆVolta ç›¸å½“ï¼‰ã§ã‚ã‚Œã°ã€**åŠç²¾åº¦æµ®å‹•å°æ•°ç‚¹ï¼ˆFP16ï¼‰**ã«ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›ã—ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼é«˜é€ŸåŒ–ã‚’å›³ã‚‹
    if device.startswith('cuda'):
        model.fuse()
        
        if torch.cuda.get_device_capability(0)[0] >= 7:  # Volta or newer
            model.model.half()
    
    # Process tomograms with parallelization
    results = []
    motors_found = 0


    # ThreadPoolExecutor ã‚’ä½¿ã£ã¦ ä¸¦åˆ—å‡¦ç†ãƒ—ãƒ¼ãƒ« ã‚’é–‹ã
    # max_workers=1 ãªã®ã§å®Ÿéš›ã¯ä¸€åº¦ã«ï¼‘ã‚¿ã‚¹ã‚¯ãšã¤ã§ã™ãŒã€ä»–ã®è¨­å®šãªã‚‰è¤‡æ•°åŒæ™‚å®Ÿè¡Œã‚‚å¯èƒ½
    # ãƒ†ã‚¹ãƒˆç”¨ãƒˆãƒ¢ã‚°ãƒ©ãƒ ã™ã¹ã¦ã«ã¤ã„ã¦ã€
    # process_tomogram é–¢æ•°ã‚’ã€ŒéåŒæœŸã‚¿ã‚¹ã‚¯ã€ã¨ã—ã¦ã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥ï¼ˆsubmitï¼‰
    # æˆ»ã£ã¦ãã‚‹ futureï¼ˆå°†æ¥ã®çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã¨ tomo_id ã‚’å¯¾å¿œã¥ã‘ã¦ä¿å­˜
    with ThreadPoolExecutor(max_workers=1) as executor:
        future_to_tomo = {}
        
        for i, tomo_id in enumerate(test_tomos, 1):
            future = executor.submit(process_tomogram, tomo_id, model, i, total_tomos)
            future_to_tomo[future] = tomo_id
        
        # Process completed futures as they complete
        for future in future_to_tomo:
            tomo_id = future_to_tomo[future]
            try:
                # Clear CUDA cache between tomograms
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    
                result = future.result()
                results.append(result)
                
                # future_to_tomo ã«ç™»éŒ²ã—ãŸã™ã¹ã¦ã® future ã«ã¤ã„ã¦ãƒ«ãƒ¼ãƒ—
                # future.result() ã§ process_tomogram ã®è¿”ã‚Šå€¤ã‚’å–å¾—ï¼ˆå®Œäº†ã‚’å¾…ã¤ï¼‰
                # çµæœã‚’ results ãƒªã‚¹ãƒˆã«è¿½åŠ 
                # Motor axis 0 ãŒ -1 ã§ãªã‘ã‚Œã°ã€Œæ¤œå‡ºã‚ã‚Šã€ã¨åˆ¤æ–­ã—ã‚«ã‚¦ãƒ³ã‚¿ã‚’å¢—åŠ ï¼†ãƒ­ã‚°å‡ºåŠ›
                # å‡¦ç†ç‡ï¼ˆä½•ä»¶ä¸­ä½•ä»¶æ¤œå‡ºã§ããŸã‹ï¼‰ã‚’éšæ™‚è¡¨ç¤º
                # ä¾‹å¤–ãŒå‡ºãŸå ´åˆã‚‚ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«å¤±æ•—ã›ãšã€åº§æ¨™ã‚’ -1 ã§åŸ‹ã‚ã¦ãŠã
                has_motor = not pd.isna(result['Motor axis 0'])
                if has_motor:
                    motors_found += 1
                    print(f"Motor found in {tomo_id} at position: "
                          f"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}")
                else:
                    print(f"No motor detected in {tomo_id}")
                    
                print(f"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)")
            
            except Exception as e:
                print(f"Error processing {tomo_id}: {e}")
                # Create a default entry for failed tomograms
                results.append({
                    'tomo_id': tomo_id,
                    'Motor axis 0': -1,
                    'Motor axis 1': -1,
                    'Motor axis 2': -1
                })
    
    # Create submission dataframe
    submission_df = pd.DataFrame(results)
    
    # Ensure proper column order
    submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]
    
    # Save the submission file
    submission_df.to_csv(submission_path, index=False)
    print("="*50)
    print("= Submission preview:")
    print("="*50)
    print(submission_df.head())
    return submission_df
    